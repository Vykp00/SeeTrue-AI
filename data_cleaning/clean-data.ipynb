{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9734715,"sourceType":"datasetVersion","datasetId":5957755}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-10T18:43:44.640799Z","iopub.execute_input":"2024-10-10T18:43:44.641252Z","iopub.status.idle":"2024-10-10T18:43:45.867897Z","shell.execute_reply.started":"2024-10-10T18:43:44.641208Z","shell.execute_reply":"2024-10-10T18:43:45.866611Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Constants** for counting chunks, lines in config_file and for the config_file","metadata":{}},{"cell_type":"code","source":"chunk_num_custom = 1\nc = 1\nconfig = pd.DataFrame(columns=[\"result\",\"filename\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:43:48.786088Z","iopub.execute_input":"2024-10-10T18:43:48.786768Z","iopub.status.idle":"2024-10-10T18:43:48.796872Z","shell.execute_reply.started":"2024-10-10T18:43:48.786719Z","shell.execute_reply":"2024-10-10T18:43:48.795422Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Two functions for dataset formation: the first one to convertion milliseconds to seconds and count from 1 to 9 seconds as integers in each chunck of frames, the second for dividing on chunks","metadata":{}},{"cell_type":"code","source":"def convert_timestamp_to_seconds(df, name):\n    # Convert 'Timestamp' from milliseconds to seconds\n    df['seconds'] = df[' Timestamp '] / 1000\n\n    # Normalize the time to count from 1 to 9 seconds\n    min_time = df['seconds'].min()\n    df[' Timestamp '] = ((df['seconds'] - min_time) % 9 + 1).astype(int)\n    df = df.drop('chunk',axis=1)\n    df = df.drop('seconds',axis=1)\n    df.to_csv(name, index=False) \n    \n    return df[[' Timestamp ']]","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:43:50.338167Z","iopub.execute_input":"2024-10-10T18:43:50.339241Z","iopub.status.idle":"2024-10-10T18:43:50.347675Z","shell.execute_reply.started":"2024-10-10T18:43:50.339193Z","shell.execute_reply":"2024-10-10T18:43:50.346059Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_and_save_chunks(c, chunk_num_custom, className):\n    # Assuming the timestamp column is named 'timestamp' in milliseconds\n    df['seconds'] = df[' Timestamp '] / 1000  # Convert milliseconds to seconds\n    # Group into chunks of 10 seconds\n    df['chunk'] = (df['seconds'] // 9).astype(int)\n    # Iterate through each chunk and save to a separate CSV file\n    for chunk_num, chunk_data in df.groupby('chunk'):\n        # Define the filename for the chunk\n        output_file = f'{chunk_num_custom}_{className}.csv'\n        chunk_num_custom = chunk_num_custom + 1;\n        config.loc[c,['result','filename']] = className,output_file\n        convert_timestamp_to_seconds(chunk_data, output_file)\n        c = c+1\n        \n        print(f'Saved: {output_file}')\n    return c, chunk_num_custom","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:43:52.444107Z","iopub.execute_input":"2024-10-10T18:43:52.445387Z","iopub.status.idle":"2024-10-10T18:43:52.454291Z","shell.execute_reply.started":"2024-10-10T18:43:52.445324Z","shell.execute_reply":"2024-10-10T18:43:52.453015Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# The main code part, where we are getting the file and make sume manipulations with data:\n\n    1. Drop columns: \"Frame number \",\" Score (right) \",\" Score (left) \", \" Pupil area (right) px \", \n    \" Pupil area (left) px \",\" Scene picture number \",\" System time Year:Month:Day:Hour:Minute:Second:Milliseconds \",\n    \" Cornea center X (right) \", \" Cornea center Y (right) \",\" Cornea center Z (right) \",\" Cornea center X (left) \", \n    \" Cornea center Y (left) \",\" Cornea center Z (left) \",\" Calibration error \", \" Client event\"\n    \n    2. \"Eye event\" column with empty value is changed on \"NA\" value, because glasses cannot recognize the eye event, but coordinates can be good for classification\n    \n    3. We have dropped some rows base on \"Score\", if the score is less of this value, it is dropped. After our own research we found that for each activity this value is different. For reading: 0.3. For walking: 0.17. For playing: 0.23.\n    After it the column with \"Score\" value was also dropped.\n\n    4. ' Pupil area (right) sq mm ', ' Pupil area (left) sq mm ' were normalized from 0 to 1 by MinMaxScaler\n\n    5. Finally, data was divided on chancks and timestamp data was reclassified. Everything was saved and data with file name and class was written in configuration file","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        input_file = os.path.join(dirname, filename)\n        print(filename)\n        className = filename.split(\"_\")[0]\n        df = pd.read_csv(input_file)\n        COL_LIST = [\"Frame number \",\" Score (right) \",\" Score (left) \", \" Pupil area (right) px \", \" Pupil area (left) px \",\" Scene picture number \",\" System time Year:Month:Day:Hour:Minute:Second:Milliseconds \",\" Cornea center X (right) \", \" Cornea center Y (right) \",\" Cornea center Z (right) \",\" Cornea center X (left) \", \" Cornea center Y (left) \",\" Cornea center Z (left) \",\" Calibration error \", \" Client event\"]\n        df = df.drop(COL_LIST,axis=1)\n        value = 0\n        # change value for dropping depending on the class\n        if(className == 'reading'): \n            value = 0.30\n        elif (className == 'walking'):\n            value = 0.17\n        elif (className == 'playing'):\n            value = 0.23\n        score = df[(df[' Score '] <= value)].index\n        df.drop(score, inplace=True)\n        df[' Eye event '] = df[' Eye event '].replace(\"  \", \" NA \")\n        df = df.drop(\" Score \",axis=1)\n        scaler = MinMaxScaler(feature_range=(0, 1))\n        columns_to_normalize = [' Pupil area (right) sq mm ', ' Pupil area (left) sq mm ']\n        df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n        df[columns_to_normalize] = df[columns_to_normalize].round(2)\n        c, chunk_num_custom = process_and_save_chunks(c, chunk_num_custom, className)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:43:54.566133Z","iopub.execute_input":"2024-10-10T18:43:54.566599Z","iopub.status.idle":"2024-10-10T18:43:54.577170Z","shell.execute_reply.started":"2024-10-10T18:43:54.566554Z","shell.execute_reply":"2024-10-10T18:43:54.575888Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config.to_csv(\"config_data.csv\", index=False) ","metadata":{},"outputs":[],"execution_count":null}]}